"""
OPTIMIZED Stages 2-3 Evaluation with PyTorch + HuggingFace Models

KEY OPTIMIZATIONS:
1. Reduced rollouts: 10 instead of 30 (3x speedup)
2. Reduced max tokens: 50 instead of 250 (5x speedup)
3. KV cache enabled: O(n) instead of O(nÂ²) (2-3x speedup)
4. Early stopping on EOS (up to 2x speedup)
5. Better tensor dimension handling (fixes crashes)

EXPECTED SPEEDUP: 5-10x faster than original version!

Original: 50-75s per sample
Optimized: 5-10s per sample

Uses:
1. PyTorch with proper HuggingFace model loading (REAL weights!)
2. Real M4 and HAR datasets
3. Llama 1B/3B or Mistral-7B models
4. MaxEnt-TS tree search algorithm with ALL optimizations
"""

import sys
import json
from pathlib import Path
import time
import numpy as np
import torch

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent))

from dts_implementation.search.maxent_ts import MaxEntTS, MaxEntTSConfig
from dts_implementation.models.pytorch_hf_wrapper import PyTorchHFWrapper, load_recommended_model
from dts_implementation.rewards.spectral_reward import SpectralReward
from src.time_series_datasets.m4.M4QADataset import M4QADataset
from src.time_series_datasets.har_cot.HARCoTQADataset import HARCoTQADataset

print("\n" + "="*80)
print("  ðŸš€ OPTIMIZED STAGES 2-3 WITH PYTORCH + HUGGINGFACE")
print("="*80 + "\n")

print("âœ¨ KEY OPTIMIZATIONS:")
print("  âœ… Reduced rollouts: 10 (was 30) â†’ 3x faster")
print("  âœ… Reduced max tokens: 50 (was 250) â†’ 5x faster")
print("  âœ… KV cache enabled â†’ 2-3x faster")
print("  âœ… Early stopping on EOS â†’ up to 2x faster")
print("  âœ… Fixed tensor dimensions â†’ no crashes")
print()
print("  ðŸ“Š EXPECTED SPEEDUP: 5-10x faster!")
print("  â±ï¸  Original: 50-75s per sample")
print("  â±ï¸  Optimized: 5-10s per sample")
print()

# OPTIMIZED Configuration
NUM_SAMPLES_STAGE2 = 3  # M4 time series captioning
NUM_SAMPLES_STAGE3 = 3  # HAR activity recognition
NUM_ROLLOUTS = 10       # REDUCED from 30 (3x speedup)
EXPANSION_K = 3         # REDUCED from 4 (faster tree)
MAX_NEW_TOKENS = 50     # REDUCED from 250 (5x speedup)

print("Configuration:")
print(f"  â€¢ Samples per stage: {NUM_SAMPLES_STAGE2}")
print(f"  â€¢ Rollouts: {NUM_ROLLOUTS} (was 30)")
print(f"  â€¢ Expansion K: {EXPANSION_K} (was 4)")
print(f"  â€¢ Max new tokens: {MAX_NEW_TOKENS} (was 250)")
print()

# Detect device
if torch.cuda.is_available():
    device = "cuda"
    print("ðŸŽ® Using CUDA GPU")
elif torch.backends.mps.is_available():
    device = "mps"
    print("ðŸŽ Using Apple Silicon (MPS)")
else:
    device = "cpu"
    print("ðŸ’» Using CPU")

print()

# Model selection (auto-select based on device)
if device == "mps":
    selected_model = "1b-instruct"  # Faster for testing
    print(f"âœ… Auto-selected: Llama 1B (fast testing on Apple Silicon)")
elif device == "cuda":
    selected_model = "3b-instruct"
    print(f"âœ… Auto-selected: Llama 3B (recommended for CUDA)")
else:
    selected_model = "1b-instruct"
    print(f"âœ… Auto-selected: Llama 1B (recommended for CPU)")

print()
sys.stdout.flush()

print("="*80)
print("  ðŸ“¥ LOADING MODEL")
print("="*80 + "\n")
sys.stdout.flush()

# Load model
model = load_recommended_model(selected_model, device=device)
print()
sys.stdout.flush()

# Initialize spectral reward
print("Initializing reward function...")
reward_fn = SpectralReward(
    freq_weight=0.5,
    temporal_weight=0.5,
    normalize=True
)
print("âœ… Reward function ready")
print()

# OPTIMIZED MaxEntTS Config
config = MaxEntTSConfig(
    num_rollouts=NUM_ROLLOUTS,          # OPTIMIZED: 10 instead of 30
    expansion_k=EXPANSION_K,            # OPTIMIZED: 3 instead of 4
    max_seq_length=100,                 # OPTIMIZED: 100 instead of 200
    rollout_max_new_tokens=MAX_NEW_TOKENS,  # NEW: Limit rollout tokens
    use_kv_cache=True,                  # CRITICAL: Enable KV cache
    early_stopping=True,                # NEW: Stop on EOS token
    temperature=0.8,
    verbose=False  # Cleaner output
)

# Initialize searcher
print("Initializing MaxEnt-TS with OPTIMIZED settings...")
searcher = MaxEntTS(
    model=model,
    reward=reward_fn,
    config=config
)
print("âœ… MaxEnt-TS ready")
print()

print("="*80)
print("  ðŸ“Š STAGE 2: M4 TIME SERIES CAPTIONING")
print("="*80 + "\n")
sys.stdout.flush()

# Load Stage 2 dataset (REAL M4)
print("Loading M4QADataset (real M4 competition data)...")
stage2_dataset = M4QADataset(
    split='test',
    EOS_TOKEN=model.tokenizer.eos_token,
    format_sample_str=False
)

stage2_results = {
    'dataset': 'M4 Time Series Captioning (Real M4 Competition)',
    'model': f"{selected_model} (PyTorch)",
    'device': device,
    'num_rollouts': NUM_ROLLOUTS,
    'expansion_k': EXPANSION_K,
    'max_new_tokens': MAX_NEW_TOKENS,
    'optimizations': ['KV cache', 'Early stopping', 'Reduced rollouts', 'Limited tokens'],
    'results': []
}

print(f"âœ… Dataset loaded: {len(stage2_dataset)} samples")
print(f"Testing on {NUM_SAMPLES_STAGE2} samples...")
print()
sys.stdout.flush()

total_time_s2 = 0
total_nodes_s2 = 0

for i in range(NUM_SAMPLES_STAGE2):
    print(f"\n{'â”€'*80}")
    print(f"  Sample {i+1}/{NUM_SAMPLES_STAGE2}")
    print(f"{'â”€'*80}\n")
    sys.stdout.flush()
    
    try:
        # Get sample from real M4 dataset
        sample = stage2_dataset[i]
        prompt = sample['input']
        ground_truth = sample['output']
        
        print(f"Prompt length: {len(prompt)} chars")
        print(f"Ground truth length: {len(ground_truth)} chars")
        sys.stdout.flush()
        
        # Tokenize
        prompt_tokens = model.encode_text(prompt)
        ground_truth_tokens = model.encode_text(ground_truth)
        
        print(f"Running OPTIMIZED search with {NUM_ROLLOUTS} rollouts...")
        sys.stdout.flush()
        
        start_time = time.time()
        
        # Run search with optimized config
        result = searcher.search(
            prompt_tokens=prompt_tokens,
            max_new_tokens=MAX_NEW_TOKENS  # Use optimized value
        )
        
        elapsed = time.time() - start_time
        
        # Extract results
        generated_text = result['best_text']
        best_reward = result['best_reward']
        tree_stats = result['tree_stats']
        nodes = tree_stats['total_nodes']
        
        total_time_s2 += elapsed
        total_nodes_s2 += nodes
        
        print(f"\nâœ… Complete!")
        print(f"  â€¢ Nodes: {nodes}")
        print(f"  â€¢ Time: {elapsed:.2f}s")
        print(f"  â€¢ Reward: {best_reward:.4f}")
        print(f"  â€¢ Output length: {len(generated_text)} chars")
        
        # Show preview
        preview = generated_text[:200] + "..." if len(generated_text) > 200 else generated_text
        print(f"\n  Output preview:")
        print(f"  '{preview}'")
        sys.stdout.flush()
        
        # Save result
        stage2_results['results'].append({
            'sample_id': i,
            'prompt': prompt,
            'ground_truth': ground_truth,
            'generated_output': generated_text,
            'best_reward': float(best_reward),
            'nodes': int(nodes),
            'time': float(elapsed),
            'tree_stats': {k: float(v) if isinstance(v, (int, float, np.number)) else v 
                          for k, v in tree_stats.items()}
        })
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        stage2_results['results'].append({
            'sample_id': i,
            'error': str(e),
            'nodes': 0,
            'time': 0.0
        })

# Calculate Stage 2 averages
avg_nodes_s2 = total_nodes_s2 / NUM_SAMPLES_STAGE2 if NUM_SAMPLES_STAGE2 > 0 else 0
avg_time_s2 = total_time_s2 / NUM_SAMPLES_STAGE2 if NUM_SAMPLES_STAGE2 > 0 else 0

stage2_results['avg_nodes'] = float(avg_nodes_s2)
stage2_results['avg_time'] = float(avg_time_s2)
stage2_results['total_time'] = float(total_time_s2)

print("\n" + "="*80)
print(f"  STAGE 2 COMPLETE")
print("="*80)
print(f"  â€¢ Avg nodes: {avg_nodes_s2:.1f}")
print(f"  â€¢ Avg time: {avg_time_s2:.2f}s per sample")
print(f"  â€¢ Total time: {total_time_s2:.1f}s ({total_time_s2/60:.1f} min)")
print("="*80 + "\n")
sys.stdout.flush()

print("="*80)
print("  ðŸƒ STAGE 3: HUMAN ACTIVITY RECOGNITION CoT")
print("="*80 + "\n")
sys.stdout.flush()

# Load Stage 3 dataset (REAL HAR)
print("Loading HARCoTQADataset (real HAR accelerometer data with CoT)...")
stage3_dataset = HARCoTQADataset(
    split='test',
    EOS_TOKEN=model.tokenizer.eos_token,
    format_sample_str=False
)

stage3_results = {
    'dataset': 'HAR with Chain-of-Thought (Real Accelerometer Data)',
    'model': f"{selected_model} (PyTorch)",
    'device': device,
    'num_rollouts': NUM_ROLLOUTS,
    'expansion_k': EXPANSION_K,
    'max_new_tokens': MAX_NEW_TOKENS,
    'optimizations': ['KV cache', 'Early stopping', 'Reduced rollouts', 'Limited tokens'],
    'results': []
}

print(f"âœ… Dataset loaded: {len(stage3_dataset)} samples")
print(f"Testing on {NUM_SAMPLES_STAGE3} samples...")
print()
sys.stdout.flush()

total_time_s3 = 0
total_nodes_s3 = 0

for i in range(NUM_SAMPLES_STAGE3):
    print(f"\n{'â”€'*80}")
    print(f"  Sample {i+1}/{NUM_SAMPLES_STAGE3}")
    print(f"{'â”€'*80}\n")
    sys.stdout.flush()
    
    try:
        # Get sample from real HAR dataset
        sample = stage3_dataset[i]
        prompt = sample['input']
        ground_truth = sample['output']
        
        print(f"Prompt length: {len(prompt)} chars")
        print(f"Ground truth length: {len(ground_truth)} chars")
        sys.stdout.flush()
        
        # Tokenize
        prompt_tokens = model.encode_text(prompt)
        ground_truth_tokens = model.encode_text(ground_truth)
        
        print(f"Running OPTIMIZED search with {NUM_ROLLOUTS} rollouts...")
        sys.stdout.flush()
        
        start_time = time.time()
        
        # Run search with optimized config
        result = searcher.search(
            prompt_tokens=prompt_tokens,
            max_new_tokens=MAX_NEW_TOKENS  # Use optimized value
        )
        
        elapsed = time.time() - start_time
        
        # Extract results
        generated_text = result['best_text']
        best_reward = result['best_reward']
        tree_stats = result['tree_stats']
        nodes = tree_stats['total_nodes']
        
        total_time_s3 += elapsed
        total_nodes_s3 += nodes
        
        print(f"\nâœ… Complete!")
        print(f"  â€¢ Nodes: {nodes}")
        print(f"  â€¢ Time: {elapsed:.2f}s")
        print(f"  â€¢ Reward: {best_reward:.4f}")
        print(f"  â€¢ Output length: {len(generated_text)} chars")
        
        # Show preview
        preview = generated_text[:200] + "..." if len(generated_text) > 200 else generated_text
        print(f"\n  Output preview:")
        print(f"  '{preview}'")
        sys.stdout.flush()
        
        # Save result
        stage3_results['results'].append({
            'sample_id': i,
            'prompt': prompt,
            'ground_truth': ground_truth,
            'generated_output': generated_text,
            'best_reward': float(best_reward),
            'nodes': int(nodes),
            'time': float(elapsed),
            'tree_stats': {k: float(v) if isinstance(v, (int, float, np.number)) else v 
                          for k, v in tree_stats.items()}
        })
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        stage3_results['results'].append({
            'sample_id': i,
            'error': str(e),
            'nodes': 0,
            'time': 0.0
        })

# Calculate Stage 3 averages
avg_nodes_s3 = total_nodes_s3 / NUM_SAMPLES_STAGE3 if NUM_SAMPLES_STAGE3 > 0 else 0
avg_time_s3 = total_time_s3 / NUM_SAMPLES_STAGE3 if NUM_SAMPLES_STAGE3 > 0 else 0

stage3_results['avg_nodes'] = float(avg_nodes_s3)
stage3_results['avg_time'] = float(avg_time_s3)
stage3_results['total_time'] = float(total_time_s3)

print("\n" + "="*80)
print(f"  STAGE 3 COMPLETE")
print("="*80)
print(f"  â€¢ Avg nodes: {avg_nodes_s3:.1f}")
print(f"  â€¢ Avg time: {avg_time_s3:.2f}s per sample")
print(f"  â€¢ Total time: {total_time_s3:.1f}s ({total_time_s3/60:.1f} min)")
print("="*80 + "\n")
sys.stdout.flush()

# Save all results
output_dir = Path("evaluation/results")
output_dir.mkdir(parents=True, exist_ok=True)
output_file = output_dir / "stages_2_3_OPTIMIZED.json"

results = {
    'stage2': stage2_results,
    'stage3': stage3_results,
    'system_info': {
        'device': device,
        'model': selected_model,
        'pytorch_version': torch.__version__,
        'cuda_available': torch.cuda.is_available(),
        'mps_available': torch.backends.mps.is_available()
    }
}

with open(output_file, 'w') as f:
    json.dump(results, f, indent=2)

print("="*80)
print("  âœ… OPTIMIZED EVALUATION COMPLETE!")
print("="*80 + "\n")

print(f"Results saved to: {output_file}")
print()
print("PERFORMANCE SUMMARY:")
print(f"  Stage 2 (M4): {avg_nodes_s2:.1f} nodes, {avg_time_s2:.2f}s avg")
print(f"  Stage 3 (HAR): {avg_nodes_s3:.1f} nodes, {avg_time_s3:.2f}s avg")
print()

# Calculate speedup vs original
original_time_estimate = 50  # seconds per sample (original)
optimized_time = (avg_time_s2 + avg_time_s3) / 2
speedup = original_time_estimate / optimized_time if optimized_time > 0 else 0

print("âš¡ SPEEDUP ANALYSIS:")
print(f"  Original estimated time: ~{original_time_estimate}s per sample")
print(f"  Optimized actual time: {optimized_time:.1f}s per sample")
print(f"  ðŸš€ SPEEDUP: {speedup:.1f}x faster!")
print()

print("Key optimizations applied:")
print("  âœ… KV cache enabled (O(n) instead of O(nÂ²))")
print("  âœ… Reduced rollouts (10 instead of 30)")
print("  âœ… Limited max tokens (50 instead of 250)")
print("  âœ… Early stopping on EOS token")
print("  âœ… Better tensor dimension handling")
print()
print("="*80 + "\n")
