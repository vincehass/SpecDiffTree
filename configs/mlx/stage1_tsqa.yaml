experiment:
  name: "stage1_tsqa_mlx"
  tags: ["mlx", "stage1", "tsqa", "m3max"]
  notes: "Stage 1 TSQA training with MLX on M3 Max"

dataset:
  name: "TSQA"
  task: "Multiple Choice Question Answering"
  num_samples_train: 6300
  num_samples_val: 630
  num_samples_test: 700

model:
  llm_id: "mlx-community/Llama-3.2-1B-Instruct-4bit"
  patch_size: 4
  ts_channels: 1
  encoder_hidden_dim: 128
  freeze_llm: true

training:
  num_epochs: 10
  batch_size: 4
  lr_encoder: 1.0e-4  # Learning rate
  weight_decay: 0.01
  grad_clip_norm: 1.0
  warmup_fraction: 0.05
  eval_every: 500
  save_every: 1000
  patch_size: 4
  
logging:
  wandb_project: "specdifftree"
  wandb_entity: "nadhirvincenthassen"
  log_every: 10

