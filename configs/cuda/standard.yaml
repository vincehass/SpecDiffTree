# SpecDiffTree - CUDA Training
# For NVIDIA GPU systems

experiment:
  name: "specdifftree_cuda"
  tags: ["specdifftree", "cuda", "stage1", "gpu"]
  notes: "CUDA training with NVIDIA GPU acceleration"

dataset:
  name: "TSQA"
  task: "Multiple Choice Question Answering"
  num_samples_train: 6300
  num_samples_val: 630
  num_samples_test: 700

model:
  type: "OpenTSLMSP"
  llm_id: "meta-llama/Llama-3.2-1B"
  gradient_checkpointing: false
  lora:
    enabled: false

training:
  num_epochs: 30
  batch_size: 16  # Larger batch for CUDA
  lr_encoder: 2.0e-4
  lr_projector: 1.0e-4
  lr_base: 2.0e-4
  weight_decay: 1.0e-2
  grad_clip_norm: 1.0
  warmup_fraction: 0.03
  early_stopping_patience: 5
  patch_size: 4

device:
  type: "cuda"
  
evaluation:
  metrics: ["accuracy", "loss"]
  save_predictions: true

