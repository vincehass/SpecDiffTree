# Can We Treat LLM Generation as "Diffusion"?

**TL;DR: YES, with the right interpretation!** ðŸŽ‰

---

## ðŸ” What The Documents Say

### From S-ADT.md:
> "Given a frozen, pre-trained diffusion prior p_Î¸(x|c)"

### From README.md (Line 74):
> "Uses OpenTSLM's reverse diffusion as the transition model"

### From README.md (Line 22):
> "Given OpenTSLM's frozen diffusion prior, we align it to complex rewards"

**But we know:** OpenTSLM is an autoregressive LLM, NOT a continuous diffusion model!

---

## ðŸ’¡ The Key Insight

### The terminology is **METAPHORICAL**, not literal!

What S-ADT/README mean by "diffusion" for OpenTSLM:
- **"Diffusion process"** = Autoregressive token generation
- **"Timestep t"** = Token position in sequence
- **"Denoising"** = Generating/selecting next token
- **"x_T â†’ x_0"** = [BOS] â†’ full answer sequence

This is conceptually valid! Here's why:

---

## ðŸ“Š Mapping: Diffusion â†” Autoregressive

| Continuous Diffusion | Autoregressive LLM | Interpretation |
|---------------------|-------------------|----------------|
| Noise x_T | Empty/[BOS] token | Starting state |
| Timestep t | Token position t | Sequence progress |
| Denoise: x_t â†’ x_{t-1} | Generate: tokens_0:t â†’ token_t+1 | Transition |
| Clean sample x_0 | Complete answer | Final state |
| p_Î¸(x_{t-1}\|x_t) | p_Î¸(token_t+1\|tokens_0:t) | Conditional prob |
| Sample trajectory | Sample token sequence | Path through space |

---

## âœ… Why This Makes Sense

### 1. Tree Search is General

MCTS/DTS is not specific to diffusion - it works for ANY sequential decision process:
- Go/Chess (AlphaZero)
- Text generation (MCTS for LLMs)
- Diffusion models (DTS paper)
- **Autoregressive LLMs** (our adaptation!)

### 2. Prior Work Exists

**Tree Search for Text Generation:**
- MCTS-based text generation (multiple papers)
- Beam search with value networks
- Constrained decoding with lookahead
- Speculative decoding with tree

**Discrete Diffusion for Text:**
- SUNDAE (2021) - treating text as discrete diffusion
- Diffusion-LM (2022) - continuous diffusion for text
- AR-Diffusion (2023) - bridging autoregressive and diffusion

### 3. Core Concepts Transfer

What matters for DTS â†’ LLM adaptation:

| DTS Concept | Transfers to LLMs? | How |
|-------------|-------------------|-----|
| **Tree structure** | âœ… YES | Tree of partial sequences |
| **MCTS phases** | âœ… YES | Selection/Expansion/Rollout/Backup |
| **Soft Bellman** | âœ… YES | Soft value over token choices |
| **Spectral reward** | âœ… YES | Evaluate final time series |
| **GFlowNet** | âœ… YES | Learn token selection policy |

---

## ðŸ”§ The Adaptation Strategy

### Original DTS (for continuous diffusion):

```python
# Start from noise
x_T = torch.randn(batch_size, dim)
root = MCTSNode(x_T, t=T)

for rollout in range(num_rollouts):
    # 1. SELECT: Navigate tree
    node = root
    while not node.is_leaf():
        node = select_child_boltzmann(node, temp)
    
    # 2. EXPAND: Sample next state
    if node.t > 0:
        x_prev = diffusion_model.p_sample(node.x_t, node.t)
        child = MCTSNode(x_prev, t=node.t-1, parent=node)
        node.add_child(child)
        node = child
    
    # 3. ROLLOUT: Complete to x_0
    x_0 = rollout_to_clean(node, diffusion_model)
    
    # 4. BACKUP: Soft Bellman
    r = reward(x_0)
    soft_bellman_backup(node, r, temp)
```

### Adapted DTS (for autoregressive LLM):

```python
# Start with prompt/context
tokens_0 = tokenizer.encode(prompt)  # e.g., [BOS, "Question:", ...]
root = MCTSNode(tokens_0, t=0)  # t=0 is start, not end!

max_tokens = 200
for rollout in range(num_rollouts):
    # 1. SELECT: Navigate tree of partial sequences
    node = root
    while not node.is_leaf() and node.t < max_tokens:
        node = select_child_boltzmann(node, temp)
    
    # 2. EXPAND: Sample next token
    if node.t < max_tokens:
        # Get top-k next token choices from LLM
        logits = model(node.tokens)
        top_tokens = sample_top_k(logits, k=5)
        
        for next_token in top_tokens:
            new_tokens = node.tokens + [next_token]
            child = MCTSNode(new_tokens, t=node.t+1, parent=node)
            node.add_child(child)
    
    # 3. ROLLOUT: Complete sequence
    if node.t < max_tokens:
        full_sequence = model.generate(
            node.tokens, 
            max_new_tokens=max_tokens-node.t
        )
    else:
        full_sequence = node.tokens
    
    # 4. BACKUP: Soft Bellman with spectral reward
    # Decode tokens to get predicted time series/answer
    x_0 = decode_model_output(full_sequence)
    r_task = task_accuracy(x_0, ground_truth)
    r_spectral = spectral_penalty(x_0, context)
    r = r_task - gamma * r_spectral
    
    # Backup through tree (same Soft Bellman!)
    soft_bellman_backup(node, r, temp)
```

---

## ðŸŽ¯ Key Differences: Diffusion vs LLM Adaptation

| Aspect | Diffusion DTS | LLM Adaptation |
|--------|---------------|----------------|
| **State space** | Continuous (x âˆˆ â„^d) | Discrete (token sequences) |
| **Time direction** | T â†’ 0 (denoise) | 0 â†’ T (generate) |
| **Transitions** | Stochastic denoising | Token sampling |
| **Branching** | Sample from p(x_{t-1}\|x_t) | Top-k tokens |
| **Terminal state** | Clean x_0 | Complete sequence |
| **Reward** | On x_0 | On decoded output |

---

## âœ… Why This Works for S-ADT + OpenTSLM

### 1. Prevents Greedy Collapse âœ“

**Problem:** Greedy decoding (beam search) â†’ single best path â†’ spectral collapse

**Solution:** Soft Bellman maintains distribution over paths â†’ preserves spectral content

### 2. Spectral Regularization âœ“

Even though we're generating tokens, the FINAL OUTPUT is a time series prediction!

```python
# OpenTSLM generates: "The answer is C"
# Which corresponds to: Predicted time series trajectory C
# We can compute: PSD of predicted trajectory
# And compare to: PSD of ground truth context
```

### 3. Tree Reuse âœ“

GFlowNet learns which token sequences lead to high rewards, amortizing search cost.

---

## ðŸš¨ Important Clarifications

### What We're NOT Doing:
âŒ Training a diffusion model  
âŒ Converting OpenTSLM to diffusion  
âŒ Changing OpenTSLM's architecture  

### What We ARE Doing:
âœ… Using tree search over OpenTSLM's generation  
âœ… Applying Soft Bellman to token selection  
âœ… Adding spectral rewards to final outputs  
âœ… Treating sequential generation as a "diffusion-like" process metaphorically  

---

## ðŸ“š Supporting Evidence

### From DTS Paper (Jain et al., 2025):

> "DTS is a general framework for aligning pre-trained generative models to rewards at inference time"

Key word: **GENERAL** - not specific to continuous diffusion!

### From README.md:

> "S-ADT addresses two critical failures in existing alignment methods:
> - Spectral Collapse: Greedy guidance destroys high-frequency textures
> - Computational Inefficiency: MCTS requires thousands of function evaluations"

This applies to **ANY** greedy decoding, including LLM beam search!

---

## ðŸŽ¯ Conclusion: YES, We Can Proceed!

### The Adaptation is Valid Because:

1. âœ… **Tree search is general** - applies to any sequential process
2. âœ… **Soft Bellman is general** - prevents greedy collapse in any setting
3. âœ… **Spectral rewards apply** - final output is time series
4. âœ… **Prior work exists** - MCTS for text, discrete diffusion
5. âœ… **README implies this** - talks about "OpenTSLM's diffusion" (metaphorical)

### Implementation Strategy:

```
Phase 1: OpenTSLM Wrapper
  â†“
Phase 2: Token-level Tree Search
  â†“
Phase 3: Spectral Reward on Final Output
  â†“
Phase 4: Soft Bellman Backup (already implemented!)
  â†“
Phase 5: GFlowNet for Token Selection
```

---

## ðŸš€ Next Steps

**I recommend we proceed with the LLM adaptation:**

1. âœ… Core tree search logic (already have from `dts_node.py`)
2. âœ… Soft Bellman backup (already have from `soft_bellman.py`)
3. ðŸš§ **Next:** OpenTSLM wrapper for token generation
4. ðŸš§ **Next:** Tree search over token sequences
5. ðŸš§ **Next:** Spectral reward computation
6. ðŸš§ **Next:** End-to-end testing

---

**Ready to implement?** The adaptation is theoretically sound and practically feasible! ðŸŽ‰

